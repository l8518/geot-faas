{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419c397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "from pandas.core.common import flatten\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "OUTPUT_BATCH_PATH=\"data/batches\"\n",
    "OUTPUT_MEASUREMENT_STATS_PATH=\"data/measurements\"\n",
    "Path(OUTPUT_BATCH_PATH).mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT_MEASUREMENT_STATS_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21bbe5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get Experimentname\n",
    "# if len(sys.argv) == 2:\n",
    "#     experimentname = sys.argv[1]\n",
    "# else:\n",
    "#     experimentname = input(\"Enter experiment name:\")\n",
    "# extracted_path = os.path.join(\"./data/extract/\", experimentname)\n",
    "experimentname = \"gtbf\"\n",
    "extracted_path = os.path.join(\"./data/extract/\", experimentname)\n",
    "scanned_dir = list(os.scandir(extracted_path))\n",
    "datafolders = list(filter(lambda x: x.is_dir(), scanned_dir))\n",
    "invocation_files = list(filter(lambda x: x.is_file(), scanned_dir))\n",
    "workers=multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd518b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create week batches:\n",
    "batches = {}\n",
    "for invocation_file in invocation_files:\n",
    "    file_name=Path(invocation_file).stem\n",
    "    invocation_date = datetime.strptime(file_name[:8], \"%Y%m%d\")\n",
    "    cw = invocation_date.isocalendar()[1]\n",
    "    batch_key = f\"{invocation_date.year}-{cw}\"\n",
    "    if batch_key not in batches:\n",
    "        batches[batch_key] = []\n",
    "    batches[batch_key].append(invocation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cfdfb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('src/driver/deploy_config_full.json') as json_file:\n",
    "    experiment_data = json.load(json_file)\n",
    "\n",
    "valid_regions = []\n",
    "for pr in experiment_data['experiment-provider-locations']:\n",
    "    valid_regions.append(f\"{pr['provider']}_{pr['region']}\")\n",
    "# valid_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be804d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_error(folders):   \n",
    "    measurements = {}\n",
    "    for vr in valid_regions:\n",
    "        measurements[vr] = 0\n",
    "\n",
    "    for f in folders:\n",
    "        folder_subset = Path(f).stem[19:].lower()\n",
    "        if folder_subset in measurements.keys():\n",
    "            measurements[folder_subset] += 1\n",
    "    return measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e01733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = []\n",
    "def process_batch(batch_file):\n",
    "    batch_filename=batch_file.name\n",
    "    batch_filter_key = batch_filename[:12]\n",
    "    pattern = batch_filter_key\n",
    "    driver_invocation = batch_filename[:-5]\n",
    "    folders = list(filter(lambda df: df.name.startswith(pattern), datafolders))\n",
    "    measurement = measure_error(folders)\n",
    "    lst = list(measurement.values())\n",
    "    dirty_measurement = all(lst) == 1\n",
    "    dirty_measurement_info = measurement\n",
    "        \n",
    "    dfs = []\n",
    "    for folder in folders:\n",
    "        invocation, provider, region = Path(folder).stem.split(\"_\")\n",
    "        file = os.path.join(folder, \"saafdemo-basicExperiment-0MBs-run0.csv\")\n",
    "        if os.path.exists(file):\n",
    "            df = pd.read_csv(file, skiprows=4)\n",
    "            # Drop last row --> contains metadata\n",
    "            df = df.iloc[:-1 , :]\n",
    "        else:\n",
    "            df = pd.DataFrame()\n",
    "            df.insert(0, \"error\", 'missing csv file') \n",
    "\n",
    "        df.insert(0, \"folder_uuid\", str(uuid.uuid1()))\n",
    "        df.insert(0, \"dirty_measurement\", dirty_measurement)\n",
    "        df.insert(0, \"region\", region)\n",
    "        df.insert(0, \"provider\", provider)\n",
    "        df.insert(0, \"workload_invocation\", invocation)\n",
    "        df.insert(0, \"driver_invocation\", driver_invocation)\n",
    "        dfs.append(df)\n",
    "    return { \"df\": pd.concat(dfs), \"measurements\" : measurement }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2859a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2021-36-336 - 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [04:02<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2021-34-336 - 2 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [03:58<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2021-33-336 - 3 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [03:58<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2021-32-336 - 4 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [03:57<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2021-39-336 - 5 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [03:57<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2021-37-336 - 6 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [03:57<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2021-38-336 - 7 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [03:58<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2021-35-336 - 8 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [03:57<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2021-31-336 - 9 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [03:57<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2021-30-21 - 10 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:14<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2021-40-9 - 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:05<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# process in batches:\n",
    "batch_no = 0\n",
    "for batch, batch_files in batches.items():\n",
    "    batch_no += 1\n",
    "    batch_file_length = len(batch_files)\n",
    "    batch_id = f\"{batch}-{batch_file_length}\"\n",
    "    batch_parquet = f\"{batch_id}.parquet\"\n",
    "    print(f\"Processing batch {batch_id} - {batch_no} of {len(batches)}\")\n",
    "\n",
    "    if os.path.exists(os.path.join(OUTPUT_BATCH_PATH, batch_parquet)):\n",
    "        print('batch already processed, skipping')\n",
    "        continue \n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=workers) as tpe:\n",
    "        batch_frames = list(tqdm(tpe.map(process_batch, batch_files), total=len(batch_files)))\n",
    "    batch_dataset = pd.concat([ bf['df'] for bf in batch_frames])\n",
    "    measurement_dataset = pd.DataFrame([ bf['measurements'] for bf in batch_frames])\n",
    "    batch_dataset = batch_dataset.sort_values(by=['driver_invocation', 'workload_invocation', 'provider', 'region', '1_run_id', '2_thread_id'])\n",
    "    batch_dataset.to_parquet(os.path.join(OUTPUT_BATCH_PATH, batch_parquet))\n",
    "    measurement_dataset.to_parquet(os.path.join(OUTPUT_MEASUREMENT_STATS_PATH, batch_parquet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
